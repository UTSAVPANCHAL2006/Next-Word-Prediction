{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f50b931",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to /Users/utsav/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## Data Collection\n",
    "import nltk\n",
    "nltk.download('gutenberg')\n",
    "from nltk.corpus import gutenberg\n",
    "import  pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24a61591",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dataset\n",
    "data = gutenberg.raw('shakespeare-hamlet.txt')\n",
    
    "## save to a file\n",
    "with open('hamlet.txt','w') as file:\n",
    "    file.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45f6d828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4818"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##laod the dataset\n",
    "with open('hamlet.txt','r') as file:\n",
    "    text=file.read().lower()\n",
    "\n",
    "\n",
    "\n",
    "#tokenization\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "total_words = len(tokenizer.word_index) + 1 \n",
    "total_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d03488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input sequences\n",
    "input_sequences = []\n",
    "for line in text.split('\\n'):\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "415be0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pad sequences\n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "998af3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create predictors and label\n",
    "\n",
    "X = input_sequences[:,:-1]\n",
    "y = input_sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad56f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49b8e1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define early stopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d069987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 13, 100)           481800    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 13, 150)           150600    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 13, 150)           0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 100)               100400    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4818)              486618    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1219418 (4.65 MB)\n",
      "Trainable params: 1219418 (4.65 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Define the model\n",
    "#LSTM model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout , GRU\n",
    "\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
    "lstm_model.add(LSTM(150, return_sequences=True))\n",
    "lstm_model.add(Dropout(0.2))\n",
    "lstm_model.add(LSTM(100))\n",
    "lstm_model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "#compile the model\n",
    "lstm_model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "403efcdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 13, 100)           481800    \n",
      "                                                                 \n",
      " gru_6 (GRU)                 (None, 13, 150)           113400    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 13, 150)           0         \n",
      "                                                                 \n",
      " gru_7 (GRU)                 (None, 100)               75600     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4818)              486618    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1157418 (4.42 MB)\n",
      "Trainable params: 1157418 (4.42 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#GRU RNN\n",
    "#Define the model\n",
    "\n",
    "gru_model=Sequential()\n",
    "gru_model.add(Embedding(total_words,100,input_length=max_sequence_len-1))\n",
    "gru_model.add(GRU(150,return_sequences=True))\n",
    "gru_model.add(Dropout(0.2))\n",
    "gru_model.add(GRU(100))\n",
    "gru_model.add(Dense(total_words,activation=\"softmax\"))\n",
    "\n",
    "# #Compile the model\n",
    "gru_model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "gru_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86c7adae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "644/644 [==============================] - 11s 18ms/step - loss: 6.3953 - accuracy: 0.0412 - val_loss: 7.0534 - val_accuracy: 0.0460\n",
      "Epoch 2/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 6.1495 - accuracy: 0.0502 - val_loss: 7.1364 - val_accuracy: 0.0525\n",
      "Epoch 3/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 6.0105 - accuracy: 0.0517 - val_loss: 7.1136 - val_accuracy: 0.0528\n",
      "Epoch 4/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 5.8998 - accuracy: 0.0549 - val_loss: 7.2223 - val_accuracy: 0.0577\n",
      "Epoch 5/50\n",
      "644/644 [==============================] - 11s 18ms/step - loss: 5.7860 - accuracy: 0.0595 - val_loss: 7.2993 - val_accuracy: 0.0530\n",
      "Epoch 6/50\n",
      "644/644 [==============================] - 12s 18ms/step - loss: 5.6765 - accuracy: 0.0629 - val_loss: 7.3695 - val_accuracy: 0.0600\n",
      "Epoch 7/50\n",
      "644/644 [==============================] - 11s 18ms/step - loss: 5.5599 - accuracy: 0.0674 - val_loss: 7.4374 - val_accuracy: 0.0606\n",
      "Epoch 8/50\n",
      "644/644 [==============================] - 11s 18ms/step - loss: 5.4382 - accuracy: 0.0777 - val_loss: 7.5443 - val_accuracy: 0.0635\n",
      "Epoch 9/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 5.3127 - accuracy: 0.0822 - val_loss: 7.5872 - val_accuracy: 0.0686\n",
      "Epoch 10/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 5.1884 - accuracy: 0.0902 - val_loss: 7.6849 - val_accuracy: 0.0684\n",
      "Epoch 11/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 5.0736 - accuracy: 0.0958 - val_loss: 7.7960 - val_accuracy: 0.0686\n",
      "Epoch 12/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 4.9621 - accuracy: 0.1011 - val_loss: 7.9360 - val_accuracy: 0.0666\n",
      "Epoch 13/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 4.8613 - accuracy: 0.1061 - val_loss: 8.0171 - val_accuracy: 0.0645\n",
      "Epoch 14/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 4.7591 - accuracy: 0.1124 - val_loss: 8.1319 - val_accuracy: 0.0651\n",
      "Epoch 15/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 4.6608 - accuracy: 0.1155 - val_loss: 8.2513 - val_accuracy: 0.0645\n",
      "Epoch 16/50\n",
      "644/644 [==============================] - 11s 18ms/step - loss: 4.5700 - accuracy: 0.1206 - val_loss: 8.3436 - val_accuracy: 0.0616\n",
      "Epoch 17/50\n",
      "644/644 [==============================] - 11s 18ms/step - loss: 4.4817 - accuracy: 0.1254 - val_loss: 8.4164 - val_accuracy: 0.0595\n",
      "Epoch 18/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 4.3902 - accuracy: 0.1333 - val_loss: 8.5626 - val_accuracy: 0.0593\n",
      "Epoch 19/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 4.3044 - accuracy: 0.1441 - val_loss: 8.7032 - val_accuracy: 0.0614\n",
      "Epoch 20/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 4.2251 - accuracy: 0.1508 - val_loss: 8.7953 - val_accuracy: 0.0610\n",
      "Epoch 21/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 4.1451 - accuracy: 0.1623 - val_loss: 8.9275 - val_accuracy: 0.0573\n",
      "Epoch 22/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 4.0741 - accuracy: 0.1722 - val_loss: 9.0511 - val_accuracy: 0.0575\n",
      "Epoch 23/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 4.0063 - accuracy: 0.1849 - val_loss: 9.1649 - val_accuracy: 0.0548\n",
      "Epoch 24/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 3.9275 - accuracy: 0.1950 - val_loss: 9.2844 - val_accuracy: 0.0528\n",
      "Epoch 25/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 3.8593 - accuracy: 0.2085 - val_loss: 9.3649 - val_accuracy: 0.0554\n",
      "Epoch 26/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 3.7967 - accuracy: 0.2152 - val_loss: 9.4704 - val_accuracy: 0.0523\n",
      "Epoch 27/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 3.7357 - accuracy: 0.2235 - val_loss: 9.5750 - val_accuracy: 0.0534\n",
      "Epoch 28/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 3.6754 - accuracy: 0.2376 - val_loss: 9.7036 - val_accuracy: 0.0565\n",
      "Epoch 29/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 3.6216 - accuracy: 0.2430 - val_loss: 9.8016 - val_accuracy: 0.0550\n",
      "Epoch 30/50\n",
      "644/644 [==============================] - 11s 18ms/step - loss: 3.5620 - accuracy: 0.2551 - val_loss: 9.8924 - val_accuracy: 0.0534\n",
      "Epoch 31/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 3.5123 - accuracy: 0.2634 - val_loss: 9.9583 - val_accuracy: 0.0563\n",
      "Epoch 32/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 3.4593 - accuracy: 0.2723 - val_loss: 10.0674 - val_accuracy: 0.0530\n",
      "Epoch 33/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 3.4118 - accuracy: 0.2804 - val_loss: 10.1706 - val_accuracy: 0.0519\n",
      "Epoch 34/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 3.3575 - accuracy: 0.2897 - val_loss: 10.2689 - val_accuracy: 0.0515\n",
      "Epoch 35/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 3.3118 - accuracy: 0.2987 - val_loss: 10.3210 - val_accuracy: 0.0534\n",
      "Epoch 36/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 3.2639 - accuracy: 0.3044 - val_loss: 10.4143 - val_accuracy: 0.0505\n",
      "Epoch 37/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 3.2238 - accuracy: 0.3134 - val_loss: 10.4820 - val_accuracy: 0.0513\n",
      "Epoch 38/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 3.1735 - accuracy: 0.3204 - val_loss: 10.5811 - val_accuracy: 0.0511\n",
      "Epoch 39/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 3.1249 - accuracy: 0.3282 - val_loss: 10.6755 - val_accuracy: 0.0509\n",
      "Epoch 40/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 3.0895 - accuracy: 0.3332 - val_loss: 10.7418 - val_accuracy: 0.0530\n",
      "Epoch 41/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 3.0503 - accuracy: 0.3424 - val_loss: 10.8102 - val_accuracy: 0.0505\n",
      "Epoch 42/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 3.0040 - accuracy: 0.3497 - val_loss: 10.8735 - val_accuracy: 0.0495\n",
      "Epoch 43/50\n",
      "644/644 [==============================] - 11s 16ms/step - loss: 2.9659 - accuracy: 0.3599 - val_loss: 10.9581 - val_accuracy: 0.0532\n",
      "Epoch 44/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 2.9295 - accuracy: 0.3601 - val_loss: 11.0206 - val_accuracy: 0.0482\n",
      "Epoch 45/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 2.8893 - accuracy: 0.3709 - val_loss: 11.1273 - val_accuracy: 0.0532\n",
      "Epoch 46/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 2.8522 - accuracy: 0.3806 - val_loss: 11.1831 - val_accuracy: 0.0505\n",
      "Epoch 47/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 2.8189 - accuracy: 0.3848 - val_loss: 11.2729 - val_accuracy: 0.0486\n",
      "Epoch 48/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 2.7858 - accuracy: 0.3878 - val_loss: 11.3079 - val_accuracy: 0.0528\n",
      "Epoch 49/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 2.7511 - accuracy: 0.3967 - val_loss: 11.3609 - val_accuracy: 0.0493\n",
      "Epoch 50/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 2.7104 - accuracy: 0.4033 - val_loss: 11.4417 - val_accuracy: 0.0486\n"
     ]
    }
   ],
   "source": [
    "history_lstm = lstm_model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=50,\n",
    "    validation_data=(X_test, y_test),\n",
    "    verbose=1,\n",
    "    callbacks=[]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4031a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "644/644 [==============================] - 13s 18ms/step - loss: 7.0800 - accuracy: 0.0315 - val_loss: 6.8241 - val_accuracy: 0.0251\n",
      "Epoch 2/50\n",
      "644/644 [==============================] - 11s 16ms/step - loss: 6.5329 - accuracy: 0.0400 - val_loss: 6.7888 - val_accuracy: 0.0472\n",
      "Epoch 3/50\n",
      "644/644 [==============================] - 10s 16ms/step - loss: 6.3200 - accuracy: 0.0489 - val_loss: 6.7935 - val_accuracy: 0.0507\n",
      "Epoch 4/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 6.1093 - accuracy: 0.0629 - val_loss: 6.7467 - val_accuracy: 0.0678\n",
      "Epoch 5/50\n",
      "644/644 [==============================] - 10s 16ms/step - loss: 5.8835 - accuracy: 0.0761 - val_loss: 6.8170 - val_accuracy: 0.0707\n",
      "Epoch 6/50\n",
      "644/644 [==============================] - 11s 16ms/step - loss: 5.6598 - accuracy: 0.0848 - val_loss: 6.8971 - val_accuracy: 0.0711\n",
      "Epoch 7/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 5.4482 - accuracy: 0.0937 - val_loss: 6.9513 - val_accuracy: 0.0729\n",
      "Epoch 8/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 5.2323 - accuracy: 0.1015 - val_loss: 7.0561 - val_accuracy: 0.0709\n",
      "Epoch 9/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 5.0160 - accuracy: 0.1144 - val_loss: 7.1672 - val_accuracy: 0.0740\n",
      "Epoch 10/50\n",
      "644/644 [==============================] - 11s 16ms/step - loss: 4.8047 - accuracy: 0.1239 - val_loss: 7.2455 - val_accuracy: 0.0729\n",
      "Epoch 11/50\n",
      "644/644 [==============================] - 10s 16ms/step - loss: 4.5885 - accuracy: 0.1410 - val_loss: 7.3249 - val_accuracy: 0.0688\n",
      "Epoch 12/50\n",
      "644/644 [==============================] - 11s 16ms/step - loss: 4.3839 - accuracy: 0.1645 - val_loss: 7.4273 - val_accuracy: 0.0670\n",
      "Epoch 13/50\n",
      "644/644 [==============================] - 10s 16ms/step - loss: 4.1818 - accuracy: 0.1911 - val_loss: 7.5195 - val_accuracy: 0.0697\n",
      "Epoch 14/50\n",
      "644/644 [==============================] - 10s 16ms/step - loss: 3.9924 - accuracy: 0.2205 - val_loss: 7.6046 - val_accuracy: 0.0696\n",
      "Epoch 15/50\n",
      "644/644 [==============================] - 10s 16ms/step - loss: 3.8160 - accuracy: 0.2476 - val_loss: 7.7077 - val_accuracy: 0.0694\n",
      "Epoch 16/50\n",
      "644/644 [==============================] - 10s 16ms/step - loss: 3.6469 - accuracy: 0.2766 - val_loss: 7.7740 - val_accuracy: 0.0657\n",
      "Epoch 17/50\n",
      "644/644 [==============================] - 10s 16ms/step - loss: 3.4890 - accuracy: 0.3004 - val_loss: 7.8584 - val_accuracy: 0.0647\n",
      "Epoch 18/50\n",
      "644/644 [==============================] - 10s 16ms/step - loss: 3.3414 - accuracy: 0.3267 - val_loss: 7.9620 - val_accuracy: 0.0628\n",
      "Epoch 19/50\n",
      "644/644 [==============================] - 11s 16ms/step - loss: 3.2046 - accuracy: 0.3466 - val_loss: 8.0223 - val_accuracy: 0.0598\n",
      "Epoch 20/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 3.0871 - accuracy: 0.3704 - val_loss: 8.1330 - val_accuracy: 0.0579\n",
      "Epoch 21/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 2.9695 - accuracy: 0.3871 - val_loss: 8.2056 - val_accuracy: 0.0567\n",
      "Epoch 22/50\n",
      "644/644 [==============================] - 11s 16ms/step - loss: 2.8587 - accuracy: 0.4067 - val_loss: 8.2930 - val_accuracy: 0.0589\n",
      "Epoch 23/50\n",
      "644/644 [==============================] - 11s 16ms/step - loss: 2.7625 - accuracy: 0.4256 - val_loss: 8.3579 - val_accuracy: 0.0569\n",
      "Epoch 24/50\n",
      "644/644 [==============================] - 11s 16ms/step - loss: 2.6633 - accuracy: 0.4433 - val_loss: 8.4455 - val_accuracy: 0.0598\n",
      "Epoch 25/50\n",
      "644/644 [==============================] - 10s 16ms/step - loss: 2.5816 - accuracy: 0.4564 - val_loss: 8.5136 - val_accuracy: 0.0626\n",
      "Epoch 26/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 2.4946 - accuracy: 0.4735 - val_loss: 8.6022 - val_accuracy: 0.0577\n",
      "Epoch 27/50\n",
      "644/644 [==============================] - 11s 16ms/step - loss: 2.4154 - accuracy: 0.4896 - val_loss: 8.6751 - val_accuracy: 0.0595\n",
      "Epoch 28/50\n",
      "644/644 [==============================] - 10s 16ms/step - loss: 2.3480 - accuracy: 0.5031 - val_loss: 8.7221 - val_accuracy: 0.0598\n",
      "Epoch 29/50\n",
      "644/644 [==============================] - 10s 16ms/step - loss: 2.2756 - accuracy: 0.5137 - val_loss: 8.8064 - val_accuracy: 0.0569\n",
      "Epoch 30/50\n",
      "644/644 [==============================] - 10s 16ms/step - loss: 2.2153 - accuracy: 0.5265 - val_loss: 8.8627 - val_accuracy: 0.0604\n",
      "Epoch 31/50\n",
      "644/644 [==============================] - 10s 16ms/step - loss: 2.1459 - accuracy: 0.5379 - val_loss: 8.9222 - val_accuracy: 0.0589\n",
      "Epoch 32/50\n",
      "644/644 [==============================] - 10s 16ms/step - loss: 2.0981 - accuracy: 0.5469 - val_loss: 8.9949 - val_accuracy: 0.0589\n",
      "Epoch 33/50\n",
      "644/644 [==============================] - 10s 16ms/step - loss: 2.0370 - accuracy: 0.5587 - val_loss: 9.0526 - val_accuracy: 0.0567\n",
      "Epoch 34/50\n",
      "644/644 [==============================] - 10s 16ms/step - loss: 1.9820 - accuracy: 0.5726 - val_loss: 9.1181 - val_accuracy: 0.0567\n",
      "Epoch 35/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 1.9356 - accuracy: 0.5770 - val_loss: 9.1927 - val_accuracy: 0.0567\n",
      "Epoch 36/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 1.8855 - accuracy: 0.5887 - val_loss: 9.2449 - val_accuracy: 0.0546\n",
      "Epoch 37/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 1.8373 - accuracy: 0.5949 - val_loss: 9.2935 - val_accuracy: 0.0528\n",
      "Epoch 38/50\n",
      "644/644 [==============================] - 10s 16ms/step - loss: 1.7956 - accuracy: 0.6036 - val_loss: 9.3453 - val_accuracy: 0.0567\n",
      "Epoch 39/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 1.7491 - accuracy: 0.6157 - val_loss: 9.4015 - val_accuracy: 0.0583\n",
      "Epoch 40/50\n",
      "644/644 [==============================] - 10s 16ms/step - loss: 1.7222 - accuracy: 0.6228 - val_loss: 9.4593 - val_accuracy: 0.0579\n",
      "Epoch 41/50\n",
      "644/644 [==============================] - 10s 16ms/step - loss: 1.6835 - accuracy: 0.6270 - val_loss: 9.5162 - val_accuracy: 0.0532\n",
      "Epoch 42/50\n",
      "644/644 [==============================] - 10s 16ms/step - loss: 1.6470 - accuracy: 0.6340 - val_loss: 9.5821 - val_accuracy: 0.0552\n",
      "Epoch 43/50\n",
      "644/644 [==============================] - 10s 16ms/step - loss: 1.6127 - accuracy: 0.6406 - val_loss: 9.6205 - val_accuracy: 0.0585\n",
      "Epoch 44/50\n",
      "644/644 [==============================] - 10s 16ms/step - loss: 1.5805 - accuracy: 0.6481 - val_loss: 9.7179 - val_accuracy: 0.0538\n",
      "Epoch 45/50\n",
      "644/644 [==============================] - 10s 16ms/step - loss: 1.5500 - accuracy: 0.6515 - val_loss: 9.7502 - val_accuracy: 0.0521\n",
      "Epoch 46/50\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 1.5200 - accuracy: 0.6601 - val_loss: 9.8155 - val_accuracy: 0.0528\n",
      "Epoch 47/50\n",
      "644/644 [==============================] - 11s 16ms/step - loss: 1.4917 - accuracy: 0.6659 - val_loss: 9.8484 - val_accuracy: 0.0511\n",
      "Epoch 48/50\n",
      "644/644 [==============================] - 10s 16ms/step - loss: 1.4605 - accuracy: 0.6740 - val_loss: 9.9003 - val_accuracy: 0.0519\n",
      "Epoch 49/50\n",
      "644/644 [==============================] - 10s 16ms/step - loss: 1.4350 - accuracy: 0.6780 - val_loss: 9.9456 - val_accuracy: 0.0558\n",
      "Epoch 50/50\n",
      "644/644 [==============================] - 10s 16ms/step - loss: 1.4124 - accuracy: 0.6830 - val_loss: 10.0035 - val_accuracy: 0.0511\n"
     ]
    }
   ],
   "source": [
    "history_gru = gru_model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=50,\n",
    "    validation_data=(X_test, y_test),\n",
    "    verbose=1,\n",
    "    callbacks=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3aa98ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LSTM...\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 11.4417 - accuracy: 0.0486\n",
      "Evaluating GRU...\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 10.0035 - accuracy: 0.0511\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating LSTM...\")\n",
    "lstm_loss, lstm_acc = lstm_model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"Evaluating GRU...\")\n",
    "gru_loss, gru_acc = gru_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df31be50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved GRU model as best_nextword_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utsav/Desktop/Project/next word prediction/.venv/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gru_model.save(\"nextword_model.h5\")\n",
    "print(\"Saved GRU model as best_nextword_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "539e0543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"tokenizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
